# Evaluation Dataset Preparation Best Practices

## Overview

There are several ways to prepare evaluation datasets for your AI applications. Each approach has its own advantages and is suitable for different scenarios and requirements.

## Ways to Prepare Evaluation Datasets

### Option 1: Run to Collect Data

**Description**: Execute your application or agent directly with inputs to collect evaluation data.

**Advantages**:
- Captures real application behavior and actual response patterns

**When to Use**:
- When you need realistic data that reflects actual usage patterns

#### What Data to Collect

Your evaluation dataset should include the following components:

**Required Data**:
- **Input**: The complete input context provided to your application/agent, including:
  - User query, prompt, or request (text)
  - Input files and their contents
  - Workspace state and folder structures
  - Configuration files or settings
  - Environment variables or context
  - Any other contextual information the agent uses
- **Final Output**: The complete response generated by your application/agent, including:
  - Text responses, answers, or explanations
  - Generated files and workspace changes (for agents that create, modify, or delete files and folders):
    - Created files and their contents
    - Modified files with before/after snapshots
    - Folder structures and organization
    - Configuration files, code files, documentation
    - Any workspace state changes

**Optional Data**:
- **Conversation Histories**: List of messages capturing the full interaction flow, including:
  - User messages
  - Assistant responses
  - Tool calls and results
  - System messages
  - Any intermediate reasoning steps

  *Note: Conversation histories are optional because some SDKs do not return conversation histories in their responses. In such cases, conversation histories can be obtained through tracing infrastructure.*

{{#sdk_specific_practices}}
{{{sdk_specific_practices}}}
{{/sdk_specific_practices}}

### Option 2: Synthetic Data Generation

**Description**: Generate synthetic evaluation data using templates, rules, or other AI models.

**Advantages**:
- Create large, diverse datasets quickly and cost-effectively
- No dependency on application execution or external services

**When to Use**:
- When you need to test specific scenarios that are rare in real usage
- When real user data is not available, insufficient, or contains sensitive information